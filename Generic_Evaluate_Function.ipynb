{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using Theano backend.\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "\n",
    "\"I have imported the word embeddings text rank code as textrank_new\"\n",
    "import textrank_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TestDoc :\n",
    "Every test file is an object with these attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestDoc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.text = ''\n",
    "        self.keywords = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading a directory with test documents\n",
    "os.chdir(\"...\")\n",
    "input_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funtion evaluate :\n",
    "Takes in the input directiry . Reads every test file and then its corresponding .key file . Calls another function to get the keywords generated by another algorithms and then compares them with the manual keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate( input_dir , object_algo , top = 5):\n",
    "    \n",
    "    test_set = {} \n",
    "    \n",
    "    for docs in os.listdir(input_dir):\n",
    "        file_reader = io.open(os.path.join(input_dir,docs), 'r' , encoding=\"iso-8859-1\")\n",
    "        file_name = docs[:-4]\n",
    "        if file_name not in test_set:\n",
    "            d = TestDoc(file_name)\n",
    "        else:\n",
    "            d = test_set[file_name]\n",
    "\n",
    "        if not docs.endswith(\".txt\"):\n",
    "            continue\n",
    "        \n",
    "        text = file_reader.read()\n",
    "        d.text = text\n",
    "   \n",
    "        # get document keywords\n",
    "        if file_name == '~$C-1':\n",
    "            continue\n",
    "            \n",
    "        file_reader = open(os.path.join(input_dir,file_name + \".key\"), 'r')\n",
    "        manual_keywords = file_reader.read()\n",
    "        for line in manual_keywords.split('\\n'):\n",
    "            line = line.rstrip().lower()\n",
    "            if len(line) > 0:\n",
    "                if '\\t' in line:\n",
    "                    d.keywords.append(line[0:line.find('\\t')])\n",
    "                else:\n",
    "                    d.keywords.append(line)\n",
    "\n",
    "        # add document to test set\n",
    "        test_set[file_name] = d\n",
    "   \n",
    "\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "\n",
    "    \n",
    "    for test_doc in test_set.values():\n",
    "        #if test_doc.name == '~$C-1':\n",
    "           # continue\n",
    "        print('document', test_doc.text)\n",
    "        print(len(test_doc.keywords), 'manual keywords: ', test_doc.keywords)\n",
    "        ## A SEPERATE FUNCTION IS CALLED TO RUN THE ALGORITHM AND GET THE KEYWORDS GENERATED \n",
    "        \n",
    "        keywords = get_keywords(input_dir , test_doc.name)\n",
    "        print('Algorithm keywords:', keywords)\n",
    "        num_manual_keywords = len(test_doc.keywords)\n",
    "        correct = 0\n",
    "        for i in range(0,min(top, len(keywords))):\n",
    "            if keywords[i][0] in set(test_doc.keywords):\n",
    "                correct += 1\n",
    "        total_precision += correct/float(len(keywords))\n",
    "        total_recall += correct/float(num_manual_keywords)\n",
    "        print('correct:', correct, 'out of', num_manual_keywords)\n",
    "\n",
    "    \n",
    "    avg_precision = round(total_precision*100/float(len(test_set)), 2)\n",
    "    avg_recall = round(total_recall*100/float(len(test_set)), 2)\n",
    "\n",
    "    avg_fmeasure = round(2*avg_precision*avg_recall/(avg_precision + avg_recall), 2)\n",
    "\n",
    "    print(\"Precision\", avg_precision, \"Recall\", avg_recall, \"F-Measure\", avg_fmeasure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_keywords(input_dir ,file_name , algo = \"textrank\"):\n",
    "    \n",
    "    import spacy\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    text = io.open(os.path.join(input_dir,file_name + \".txt\"), 'r' , encoding=\"iso-8859-1\").read() # open a document\n",
    "    doc = nlp(text) \n",
    "\n",
    "    \" Further algorithms and their funciton calls can be added and passed as in argument to this function\"\n",
    "    if algo == \"textrank\":\n",
    "        terms = textrank_new.key_terms_from_semantic_network( doc, normalize='lemma',\n",
    "                                    window_width=2, edge_weighting='embedding',\n",
    "                                    ranking_algo='pagerank', join_key_words = True,\n",
    "                                    n_keyterms=10)  \n",
    "    \n",
    "    \n",
    "    \n",
    "    return terms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate( input_dir , textrank_new , top = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
